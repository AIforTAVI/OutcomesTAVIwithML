{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import ravel\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import itertools\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "\n",
    "# define imputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "feature_scaler = StandardScaler()  \n",
    "\n",
    "# Set seed\n",
    "random.seed(2020)\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.read_excel(\"mortality_all.xlsx\")\n",
    "\n",
    "y = A[\"Mortality\"]\n",
    "y = y.ravel()\n",
    "\n",
    "X = A\n",
    "del X[\"Mortality\"]\n",
    "del X[\"ID\"]\n",
    "del X[\"STS\"]\n",
    "del X[\"STSACC\"]\n",
    "\n",
    "X10 = X[['pre_hstnt_value', 'MaxLeu', 'Septum', 'MaxCrea', 'LA', 'Fever',\n",
    "         'Perikarderguss', 'MaxCRP', 'Fluoroscopy.time', 'Contrast.agent.use']]\n",
    "\n",
    "X = imp.fit_transform(X)\n",
    "X = pd.DataFrame(data = X) \n",
    "X = feature_scaler.fit_transform(X)\n",
    "\n",
    "X10 = imp.fit_transform(X10)\n",
    "X10 = pd.DataFrame(data = X10) \n",
    "X10 = feature_scaler.fit_transform(X10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = pd.read_excel(\"Baseline August (30 features + ID).xlsx\")\n",
    "B10 = B[['TAPSE', 'RCA_Ao', 'NYHA', 'pre_hstnt_value', 'pre_krea_value',\n",
    "         'Grad der Verlaklung', 'E_E', 'Sex', 'Minimale Durchmesser', 'PA']]\n",
    "\n",
    "B = imp.fit_transform(B)\n",
    "B = pd.DataFrame(data = B) \n",
    "B = feature_scaler.fit_transform(B)  \n",
    "\n",
    "B10 = imp.fit_transform(B10)\n",
    "B10 = pd.DataFrame(data = B10) \n",
    "B10 = feature_scaler.fit_transform(B10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=4)\n",
    "cv       = StratifiedKFold(n_splits = 5, shuffle = True, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, \n",
    "                             oob_score = True, class_weight = {1: 18}) \n",
    "\n",
    "grid_param_rf = {\n",
    "    'n_estimators': [200, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "classifier_rf = GridSearchCV(estimator=rfc, param_grid=grid_param_rf, cv=inner_cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_rf    = ravel(np.zeros(len(y)))\n",
    "probas_rf10  = ravel(np.zeros(len(y)))\n",
    "probas_rfb   = ravel(np.zeros(len(y)))\n",
    "probas_rfb10 = ravel(np.zeros(len(y)))\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    fit = classifier_rf.fit(X[train], y[train])\n",
    "    probs = fit.predict_proba(X[test])\n",
    "    probas_rf[test] = probs[:, 1]\n",
    "    fit = classifier_rf.fit(X10[train], y[train])\n",
    "    probs = fit.predict_proba(X10[test])\n",
    "    probas_rf10[test] = probs[:, 1]\n",
    "    fit   = classifier_rf.fit(B[train], y[train])\n",
    "    probs = fit.predict_proba(B[test])\n",
    "    probas_rfb[test] = probs[:, 1]\n",
    "    fit   = classifier_rf.fit(B10[train], y[train])\n",
    "    probs = fit.predict_proba(B10[test])\n",
    "    probas_rfb10[test] = probs[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetwork = MLPClassifier(solver='sgd', alpha=1e-5, max_iter = 10000,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "grid_param_nn = {  \n",
    "    'activation': ['logistic','tanh','relu'],\n",
    "    'learning_rate': ['constant','invscaling'],\n",
    "    'hidden_layer_sizes':[x for x in itertools.product((3,4,5),repeat=3)]\n",
    "}\n",
    "\n",
    "classifier_nn = GridSearchCV(estimator=NeuralNetwork, param_grid=grid_param_nn, cv=inner_cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_nn    = ravel(np.zeros(len(y)))\n",
    "probas_nn10  = ravel(np.zeros(len(y)))\n",
    "probas_nnb   = ravel(np.zeros(len(y)))\n",
    "probas_nnb10 = ravel(np.zeros(len(y)))\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    fit = classifier_nn.fit(X[train], y[train])\n",
    "    probs = fit.predict_proba(X[test])\n",
    "    probas_nn[test] = probs[:, 1]\n",
    "    fit = classifier_nn.fit(X10[train], y[train])\n",
    "    probs = fit.predict_proba(X10[test])\n",
    "    probas_nn10[test] = probs[:, 1]\n",
    "    fit   = classifier_nn.fit(B[train], y[train])\n",
    "    probs = fit.predict_proba(B[test])\n",
    "    probas_nnb[test] = probs[:, 1]\n",
    "    fit   = classifier_nn.fit(B10[train], y[train])\n",
    "    probs = fit.predict_proba(B10[test])\n",
    "    probas_nnb10[test] = probs[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "svc = svm.SVC(probability = True, class_weight ={1: 18})\n",
    "\n",
    "grid_param_svm = {'kernel':('linear', 'rbf'), 'C':[1, 10], 'gamma':[.0001, .001, .01]}\n",
    "\n",
    "classifier_svm = GridSearchCV(estimator=svc, param_grid=grid_param_svm, cv=inner_cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_svm    = ravel(np.zeros(len(y)))\n",
    "probas_svm10  = ravel(np.zeros(len(y)))\n",
    "probas_svmb   = ravel(np.zeros(len(y)))\n",
    "probas_svmb10 = ravel(np.zeros(len(y)))\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    fit = classifier_svm.fit(X[train], y[train])\n",
    "    probs = fit.predict_proba(X[test])\n",
    "    probas_svm[test] = probs[:, 1]\n",
    "    fit = classifier_svm.fit(X10[train], y[train])\n",
    "    probs = fit.predict_proba(X10[test])\n",
    "    probas_svm10[test] = probs[:, 1]\n",
    "    fit   = classifier_svm.fit(B[train], y[train])\n",
    "    probs = fit.predict_proba(B[test])\n",
    "    probas_svmb[test] = probs[:, 1]\n",
    "    fit   = classifier_svm.fit(B10[train], y[train])\n",
    "    probs = fit.predict_proba(B10[test])\n",
    "    probas_svmb10[test] = probs[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "# AUC comparison adapted from\n",
    "# https://github.com/Netflix/vmaf/\n",
    "def compute_midrank(x):\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=np.float)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = 0.5*(i + j - 1)\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=np.float)\n",
    "    # Note(kazeevn) +1 is due to Python using 0-based indexing\n",
    "    # instead of 1-based in the AUC formula in the paper\n",
    "    T2[J] = T + 1\n",
    "    return T2\n",
    "\n",
    "\n",
    "\n",
    "def fastDeLong(predictions_sorted_transposed, label_1_count, ordered_sample_weight):\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=np.float)\n",
    "    ty = np.empty([k, n], dtype=np.float)\n",
    "    tz = np.empty([k, m + n], dtype=np.float)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank(positive_examples[r, :])\n",
    "        ty[r, :] = compute_midrank(negative_examples[r, :])\n",
    "        tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n",
    "    aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / n\n",
    "    v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def calc_pvalue(aucs, sigma):\n",
    "    l = np.array([[1, -1]])\n",
    "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, sigma), l.T))\n",
    "    return np.log10(2) + scipy.stats.norm.logsf(z, loc=0, scale=1) / np.log(10)\n",
    "\n",
    "\n",
    "def compute_ground_truth_statistics(ground_truth, sample_weight=None):\n",
    "    assert np.array_equal(np.unique(ground_truth), [0, 1])\n",
    "    order = (-ground_truth).argsort()\n",
    "    label_1_count = int(ground_truth.sum())\n",
    "    if sample_weight is None:\n",
    "        ordered_sample_weight = None\n",
    "    else:\n",
    "        ordered_sample_weight = sample_weight[order]\n",
    "\n",
    "    return order, label_1_count, ordered_sample_weight\n",
    "\n",
    "\n",
    "def delong_roc_variance(ground_truth, predictions):\n",
    "    sample_weight = None\n",
    "    order, label_1_count, ordered_sample_weight = compute_ground_truth_statistics(\n",
    "        ground_truth, sample_weight)\n",
    "    predictions_sorted_transposed = predictions[np.newaxis, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count, ordered_sample_weight)\n",
    "    assert len(aucs) == 1, \"There is a bug in the code, please forward this to the developers\"\n",
    "    return aucs[0], delongcov\n",
    "\n",
    "\n",
    "def delong_roc_test(ground_truth, predictions_one, predictions_two):\n",
    "    sample_weight = None\n",
    "    order, label_1_count, ordered_sample_weight = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = np.vstack((np.asarray(predictions_one), np.asarray(predictions_two)))[:, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count, ordered_sample_weight)\n",
    "    return 10**calc_pvalue(aucs, delongcov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values comparing all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08149959]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delong_roc_test(y, probas_rf, probas_rf10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02711955]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delong_roc_test(y, probas_nn, probas_nn10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00286767]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delong_roc_test(y, probas_svm, probas_svm10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-values comparing baseline features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07968427]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delong_roc_test(y, probas_rfb, probas_rfb10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03528414]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delong_roc_test(y, probas_nnb, probas_nnb10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31338372]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delong_roc_test(y, probas_svmb, probas_svmb10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
